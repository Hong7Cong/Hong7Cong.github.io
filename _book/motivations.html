<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Motivations | A Minimal Book Example</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.33 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Motivations | A Minimal Book Example" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Motivations | A Minimal Book Example" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Yihui Xie" />


<meta name="date" content="2023-05-30" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="intro.html"/>
<link rel="next" href="images-comparison.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prerequisites</a></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a></li>
<li class="chapter" data-level="3" data-path="motivations.html"><a href="motivations.html"><i class="fa fa-check"></i><b>3</b> Motivations</a>
<ul>
<li class="chapter" data-level="3.1" data-path="motivations.html"><a href="motivations.html#context"><i class="fa fa-check"></i><b>3.1</b> Context</a></li>
<li class="chapter" data-level="3.2" data-path="motivations.html"><a href="motivations.html#problem-statement"><i class="fa fa-check"></i><b>3.2</b> Problem statement</a></li>
<li class="chapter" data-level="3.3" data-path="motivations.html"><a href="motivations.html#related-works"><i class="fa fa-check"></i><b>3.3</b> Related works</a></li>
<li class="chapter" data-level="3.4" data-path="motivations.html"><a href="motivations.html#revisit-siamese-network-for-severity-ranking"><i class="fa fa-check"></i><b>3.4</b> Revisit Siamese Network for Severity Ranking</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="motivations.html"><a href="motivations.html#similarity-siamese-network-review"><i class="fa fa-check"></i><b>3.4.1</b> Similarity Siamese Network <em>(review)</em></a></li>
<li class="chapter" data-level="3.4.2" data-path="motivations.html"><a href="motivations.html#preferred-siamese-network-main-focus"><i class="fa fa-check"></i><b>3.4.2</b> Preferred Siamese Network <em>(main focus)</em></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="images-comparison.html"><a href="images-comparison.html"><i class="fa fa-check"></i><b>4</b> Images Comparison</a>
<ul>
<li class="chapter" data-level="4.1" data-path="images-comparison.html"><a href="images-comparison.html#preliminary"><i class="fa fa-check"></i><b>4.1</b> Preliminary</a></li>
<li class="chapter" data-level="4.2" data-path="images-comparison.html"><a href="images-comparison.html#siaseme-network"><i class="fa fa-check"></i><b>4.2</b> Siaseme Network</a></li>
<li class="chapter" data-level="4.3" data-path="images-comparison.html"><a href="images-comparison.html#flow-vectors-special-case"><i class="fa fa-check"></i><b>4.3</b> Flow vectors (Special Case)</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="explain-pair-wise-comparison.html"><a href="explain-pair-wise-comparison.html"><i class="fa fa-check"></i><b>5</b> Explain Pair-wise Comparison</a>
<ul>
<li class="chapter" data-level="5.1" data-path="explain-pair-wise-comparison.html"><a href="explain-pair-wise-comparison.html#p-lime"><i class="fa fa-check"></i><b>5.1</b> p-LIME</a></li>
<li class="chapter" data-level="5.2" data-path="explain-pair-wise-comparison.html"><a href="explain-pair-wise-comparison.html#pgradcam"><i class="fa fa-check"></i><b>5.2</b> pGradCAM</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="problems.html"><a href="problems.html"><i class="fa fa-check"></i><b>6</b> Problems</a>
<ul>
<li class="chapter" data-level="6.1" data-path="problems.html"><a href="problems.html#the-training-is-not-converged"><i class="fa fa-check"></i><b>6.1</b> The training is not converged</a></li>
<li class="chapter" data-level="6.2" data-path="problems.html"><a href="problems.html#unbalance-datassets"><i class="fa fa-check"></i><b>6.2</b> Unbalance datassets</a></li>
<li class="chapter" data-level="6.3" data-path="problems.html"><a href="problems.html#unaligned-unregistered-datasets"><i class="fa fa-check"></i><b>6.3</b> Unaligned Unregistered datasets</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="explain-pair-wise-comparison-1.html"><a href="explain-pair-wise-comparison-1.html"><i class="fa fa-check"></i><b>7</b> Explain pair-wise comparison</a></li>
<li class="chapter" data-level="8" data-path="future-work.html"><a href="future-work.html"><i class="fa fa-check"></i><b>8</b> Future work</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Minimal Book Example</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="motivations" class="section level1 hasAnchor" number="3">
<h1><span class="header-section-number">Chapter 3</span> Motivations<a href="motivations.html#motivations" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>In this section, we draw a big picture and define our ranking problems and sub-problems through the thinking flow of the authors. You may have different approaches. Feel free to think differently.</p>
<div id="context" class="section level2 hasAnchor" number="3.1">
<h2><span class="header-section-number">3.1</span> Context<a href="motivations.html#context" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Imagine that you are given a list of images, you will have to order the images base Before diving into severity ranking, let review what is learn-to-rank in machine learning.</p>
<p>“Any system that presents results to a user, ordered by a utility function that the user cares about, is performing a ranking function” - Learning to Rank using Gradient Descent, ICML.</p>
<p>In our particular case, the results are list of images and the utility function measure how severe an image is. Here, the annotation and concept may a little bit different from learn-to-rank by search engine. So, people who familiar with learn-to-rank for search engine may find this confuse.</p>
</div>
<div id="problem-statement" class="section level2 hasAnchor" number="3.2">
<h2><span class="header-section-number">3.2</span> Problem statement<a href="motivations.html#problem-statement" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Given a list of images</p>
</div>
<div id="related-works" class="section level2 hasAnchor" number="3.3">
<h2><span class="header-section-number">3.3</span> Related works<a href="motivations.html#related-works" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Given the problem of images severity ranking, there are several approach in the literature including regression, comparison, segmentation, etc. In this work, we investigate the comparison models for severity ranking.</p>
</div>
<div id="revisit-siamese-network-for-severity-ranking" class="section level2 hasAnchor" number="3.4">
<h2><span class="header-section-number">3.4</span> Revisit Siamese Network for Severity Ranking<a href="motivations.html#revisit-siamese-network-for-severity-ranking" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Siemese Network is a type of neural network architecture commonly used pair of samples (usually images) as input and output an comparison decision. It is particularly effective for tasks like severity ranking, where the goal is to compare and rank the severity of different instances. In the literature, there are two types of comparison labels, similarity labels and preferred labels.</p>
<p><strong><em>Definition 1</em></strong> (Preferred labels): Annotation that indicates a <strong>greater</strong> or <strong>less</strong> operation between two instances with respect to some pre-defined criteria.</p>
<p><strong><em>Definition</em></strong> <strong>2</strong> (Similarity labels): Annotation that indicates the <strong>similarity</strong> or <strong>dissimilarity</strong> between a pair of input instances</p>
<p>The basic idea behind a Siamese neural network is to have two identical sub-networks (often called twins or branches), which share the same weights and architecture. Each branch processes one input instance independently and extracts its features. These features are used later to minimize pre-define loss function and for XAI. Depend on which types of labels in use, we can categorize the Siamese network into two types Similarity Siamese and Preferred Siamese.</p>
<!-- In this work, we do not compare similarity/dissimilarity score between two or more images, but instead we compare severity score. For a pair of image, we consider "1" as image B have higher degree of severity than image A and "0" as image A have higher degree of severity than image B, where A, B is first and second image pass to the Siamese network. -->
<div id="similarity-siamese-network-review" class="section level3 hasAnchor" number="3.4.1">
<h3><span class="header-section-number">3.4.1</span> Similarity Siamese Network <em>(review)</em><a href="motivations.html#similarity-siamese-network-review" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="figure">
<img src="images/similarsiamese.png" style="width:75.0%" alt="" />
<p class="caption"><code>Figure 1: Similarity Siamese network [cite]</code></p>
</div>
<p>In the context of severity ranking, let’s say you have a dataset consisting of instances (usually images) with varying degrees of severity. The Siamese neural network takes pairs of instances as input, along with their corresponding severity labels. During training, the network learns to encode the instances into a lower-dimensional feature space where similar instances are closer together and dissimilar instances are farther apart.</p>
<p>The network architecture typically consists of several layers of neural units, such as convolutional layers followed by fully connected layers. The choice of architecture depends on the nature of the input data and the complexity of the severity ranking task.</p>
<p>The training process involves optimizing the network’s parameters (weights and biases) to minimize a loss function that captures the dissimilarity between pairs of instances. The most common loss function used in Siamese networks is the contrastive loss function, which penalizes pairs of instances that should be dissimilar but are too close together, and vice versa. The network adjusts its parameters based on these penalties, pushing similar instances closer together and dissimilar instances farther apart in the feature space.</p>
<p>Once the network is trained, it can be used to rank the severity of new instances. Given a pair of instances, the network computes their feature representations and measures their similarity. The severity ranking is determined by comparing the similarity scores of different pairs.</p>
<p>Siamese neural networks have been successfully applied to various tasks, including image similarity, text matching, and recommendation systems. In severity ranking, they can help automate the process of prioritizing and assigning severity levels to different instances based on their similarities and dissimilarities. The most common used Loss Function for SSN is Contrastive Loss.</p>
<p>Example 1: Let take an example to better understand the model using the above image as reference. Denote A, B <span class="math inline">\(\in R^{300 \times 300 \times 3}\)</span> as 2 images have same size (height <span class="math inline">\(\times\)</span> width <span class="math inline">\(\times\)</span> channel). The images then pass through sub-network (Resnet in this case) with shared weight. Assume that the output of each Resnet is <span class="math inline">\(\hat{p}_A \in R^{1 \times 2}\)</span> and <span class="math inline">\(\hat{p}_B \in R^{1 \times 2}\)</span> where <span class="math inline">\(\hat{p}_A\)</span> denote the probability of A belong to two class, Healthy and Glaucoma, respectively. Then calculate the Euclidian distance between <span class="math inline">\(\hat{p}_A\)</span> and <span class="math inline">\(\hat{p}_B\)</span> to get similarity measure following by contrastive loss optimization.</p>
<p><span class="math display">\[         
Contrastive Loss = \frac{1}{2} (1-y) D(\hat{p}_A, \hat{p}_B)^2 + \frac{1}{2} y \times max(0, D(\hat{p}_A, \hat{p}_B)^2
\]</span></p>
<p>The question now is that how can we get the true label <span class="math inline">\(y\)</span> (1 for similar and 0 for dissimilar) for contrastive loss minimization in case of severity ranking. This can be done by giving pair of image to medical expert and let them label it. Otherwise, consider time domain as landmarks to label similarity. Notice that, in severity ranking, there is no explicit distinction between similarity (1) and dissimilarity (0) but something fuzzy in between 0 and 1. Thus, the Achilles of Similarity Siamese in Severity Ranking is that it learn by Similarity not by the order of images. Therefore, ranking information is missing. This can be done by the Preferred Siamese Network which is described in the next sub-section.</p>
</div>
<div id="preferred-siamese-network-main-focus" class="section level3 hasAnchor" number="3.4.2">
<h3><span class="header-section-number">3.4.2</span> Preferred Siamese Network <em>(main focus)</em><a href="motivations.html#preferred-siamese-network-main-focus" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We call Siamese Network that use Preferred labels is “Preferred” Siamese Network. These types of network is recently introduced by group of authors [cite]. The main body of Preferred Siamese Network is similar to that of Similarity Siamese. The different is that, the output of each Resnet have dimension of one and the true label <span class="math inline">\(y\)</span> is not similarity measure but preferred measure.</p>
<div class="figure">
<img src="images/preferedsiamese.png" style="width:75.0%" alt="" />
<p class="caption"><code>Figure 1: Preferred Siamese network [cite]</code></p>
</div>
<p>Example 2: Let input dimension the same as in example 1. the output of each Resnet have dimension of one, denote severity score <span class="math inline">\(\hat{p}_A\)</span> and <span class="math inline">\(\hat{p}_B \in R\)</span>, and the true label <span class="math inline">\(y\)</span> denote “1” as image B have higher degree of severity than image A and “0” as image A have higher degree of severity than image B. Two score of two images are concatenated into one vector of two dimension before the Loss Function is computed.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="intro.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="images-comparison.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/02-literature.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
