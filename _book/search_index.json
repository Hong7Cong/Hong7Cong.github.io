[["index.html", "Image Comparasion Blog Chapter 1 Prerequisites", " Image Comparasion Blog Hong Nguyen 2023-04-19 Chapter 1 Prerequisites This is a sample book written in Markdown. You can use anything that Pandoc’s Markdown supports, e.g., a math equation \\(a^2 + b^2 = c^2\\). The bookdown package can be installed from CRAN or Github: install.packages(&quot;bookdown&quot;) # or the development version # devtools::install_github(&quot;rstudio/bookdown&quot;) Remember each Rmd file contains one and only one chapter, and a chapter is defined by the first-level heading #. To compile this example to PDF, you need XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): https://yihui.name/tinytex/. "],["intro.html", "Chapter 2 Introduction", " Chapter 2 Introduction The original idea of learning to rank is to serve the purpose of search engines. People usually use search engines as a very basic example of learning to rank due to their simple idea and explanation. However, there is some case that L2R apply to but have not been mentioned very much in the literature. In this short article, I will talk about Learning to Rank beyond Search Engines. Concretely, we can learn to rank without explicit query. Firstly, the general definition of a ranking function given by an ICML paper is stated as follows. “Any system that presents results to a user, ordered by a utility function that the user cares about, is performing a ranking function” - Learning to Rank using Gradient Descent, ICML. A common example is search engines, for example from the Web or from an intranet. For this problem, the data consists of a set of queries, and for each query, a set of returned documents. In the training phase, some query/document pairs are labeled for relevance (“excellent match”, “good match”, etc.). Only those documents returned for a given query are to be ranked against each other. Thus, rather than consisting of a single set of objects to be ranked amongst each other, the data is instead partitioned by a query. Here, the “utility function” is a query, it is an explicit function that tells the model to order documents from the most relevant documents to the least based on similarity measure.However, it is natural to think that, can we want to rank things without a query, or with implicit queries. For example, given a set of medical images, we want to order it from the most severe to the least. Is it a search engine problem? No, because no query, just have a list of documents (images). Is it a rank problem? Yes. Then what is the utility function here? The utility function is the definition of why one image is more severe than the others. You can write citations, too. For example, we are using the bookdown package (Xie 2023) in this sample book, which was built on top of R Markdown and knitr (Xie 2015). References "],["motivations.html", "Chapter 3 Motivations 3.1 Context 3.2 Problem statement", " Chapter 3 Motivations In this section, we draw a big picture and define our ranking problems and sub-problems through the thinking flow of the authors. You may have different approaches. Feel free to think differently. 3.1 Context Imagine that you are given a list of images, you will have to order the images base Before diving into severity ranking, let review what is learn-to-rank in machine learning. “Any system that presents results to a user, ordered by a utility function that the user cares about, is performing a ranking function” - Learning to Rank using Gradient Descent, ICML. In our particular case, the results are list of images and the utility function measure how severe an image is. Here, the annotation and concept may a little bit different from learn-to-rank by search engine. So, people who familiar with learn-to-rank for search engine may find this confuse. 3.2 Problem statement Given a list of images "],["images-comparison.html", "Chapter 4 Images Comparison 4.1 Siaseme Network 4.2 Flow vectors", " Chapter 4 Images Comparison We describe our methods in this chapter. Math can be added in body using usual syntax like this 4.1 Siaseme Network 4.2 Flow vectors "],["explain-pair-wise-comparison.html", "Chapter 5 Explain Pair-wise Comparison 5.1 p-LIME 5.2 pGradCAM", " Chapter 5 Explain Pair-wise Comparison Some significant applications are demonstrated in this chapter. Conventionally, the current XAI method only applies to one instance at a time. For instance, the classification model inputs an image and outputs a probability list for each class. Here, we consider ranking problems where we have 2 or more inputs, and we would like to explain the decision of such ranking models based on the correlation of input images. 5.1 p-LIME In this subsection, we will talk about a user-centric explainable method for ranking models. We want to explain the mechanism of DL in a user-friendly way. The user here is not computer scientists or researchers, the end user here is people/domain experts who actually use such explanations for their jobs. 5.2 pGradCAM "],["final-words.html", "Chapter 6 Final Words", " Chapter 6 Final Words We have finished a nice book. "],["explain-pair-wise-comparison-1.html", "Chapter 7 Explain pair-wise comparison", " Chapter 7 Explain pair-wise comparison This section will explain pair of images from pair-wise comparison model. "],["references.html", "References", " References "],["results.html", "Chapter 8 Results", " Chapter 8 Results This section will explain pair of images from pair-wise comparison model. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
