[["index.html", "A Minimal Book Example Chapter 1 Prerequisites", " A Minimal Book Example Yihui Xie 2023-05-25 Chapter 1 Prerequisites This is a sample book written in Markdown. You can use anything that Pandoc’s Markdown supports, e.g., a math equation \\(a^2 + b^2 = c^2\\). The bookdown package can be installed from CRAN or Github: install.packages(&quot;bookdown&quot;) # or the development version # devtools::install_github(&quot;rstudio/bookdown&quot;) Remember each Rmd file contains one and only one chapter, and a chapter is defined by the first-level heading #. To compile this example to PDF, you need XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): https://yihui.name/tinytex/. "],["intro.html", "Chapter 2 Introduction", " Chapter 2 Introduction The original idea of learning to rank is to serve the purpose of search engines. People usually use search engines as a very basic example of learning to rank due to their simple idea and explanation. However, there is some case that L2R apply to but have not been mentioned very much in the literature. In this short article, I will talk about Learning to Rank beyond Search Engines. Concretely, we can learn to rank without explicit query. Firstly, the general definition of a ranking function given by an ICML paper is stated as follows. “Any system that presents results to a user, ordered by a utility function that the user cares about, is performing a ranking function” - Learning to Rank using Gradient Descent, ICML. A common example is search engines, for example from the Web or from an intranet. For this problem, the data consists of a set of queries, and for each query, a set of returned documents. In the training phase, some query/document pairs are labeled for relevance (“excellent match”, “good match”, etc.). Only those documents returned for a given query are to be ranked against each other. Thus, rather than consisting of a single set of objects to be ranked amongst each other, the data is instead partitioned by a query. Here, the “utility function” is a query, it is an explicit function that tells the model to order documents from the most relevant documents to the least based on similarity measure.However, it is natural to think that, can we want to rank things without a query, or with implicit queries. For example, given a set of medical images, we want to order it from the most severe to the least. Is it a search engine problem? No, because no query, just have a list of documents (images). Is it a rank problem? Yes. Then what is the utility function here? The utility function is the definition of why one image is more severe than the others. You can write citations, too. For example, we are using the bookdown package (Xie 2023) in this sample book, which was built on top of R Markdown and knitr (Xie 2015). References "],["motivations.html", "Chapter 3 Motivations 3.1 Context 3.2 Problem statement 3.3 Related works 3.4 Revisit Siamese Network for Severity Ranking", " Chapter 3 Motivations In this section, we draw a big picture and define our ranking problems and sub-problems through the thinking flow of the authors. You may have different approaches. Feel free to think differently. 3.1 Context Imagine that you are given a list of images, you will have to order the images base Before diving into severity ranking, let review what is learn-to-rank in machine learning. “Any system that presents results to a user, ordered by a utility function that the user cares about, is performing a ranking function” - Learning to Rank using Gradient Descent, ICML. In our particular case, the results are list of images and the utility function measure how severe an image is. Here, the annotation and concept may a little bit different from learn-to-rank by search engine. So, people who familiar with learn-to-rank for search engine may find this confuse. 3.2 Problem statement Given a list of images 3.3 Related works Given the problem of images severity ranking, there are several approach in the literature including regression, comparison, segmentation, etc. In this work, we investigate the comparison models for severity ranking. 3.4 Revisit Siamese Network for Severity Ranking Siemese Network is a type of neural network architecture commonly used pair of samples (usually images) as input and output an comparison decision. It is particularly effective for tasks like severity ranking, where the goal is to compare and rank the severity of different instances. In the literature, there are two types of comparison labels, similarity labels and preferred labels. Definition 1 (Preferred labels): Annotation that indicates a greater or less operation between two instances with respect to some pre-defined criteria. Definition 2 (Similarity labels): Annotation that indicates the similarity or dissimilarity between a pair of input instances The basic idea behind a Siamese neural network is to have two identical sub-networks (often called twins or branches), which share the same weights and architecture. Each branch processes one input instance independently and extracts its features. These features are used later to minimize pre-define loss function and for XAI. There are two types of labels for comparison model, similarity labels and Preferred labels. Depend on which types of labels in use, we can categorize the Siamese network into two types Similarity Siamese and Preferred Siamese. 3.4.1 Similarity Siamese Network (review) Figure 1: Similarity Siamese network [cite] In the context of severity ranking, let’s say you have a dataset consisting of instances with varying degrees of severity. The Siamese neural network takes pairs of instances as input, along with their corresponding severity labels. During training, the network learns to encode the instances into a lower-dimensional feature space where similar instances are closer together and dissimilar instances are farther apart. The network architecture typically consists of several layers of neural units, such as convolutional layers followed by fully connected layers. The choice of architecture depends on the nature of the input data and the complexity of the severity ranking task. The training process involves optimizing the network’s parameters (weights and biases) to minimize a loss function that captures the dissimilarity between pairs of instances. The most common loss function used in Siamese networks is the contrastive loss function, which penalizes pairs of instances that should be dissimilar but are too close together, and vice versa. The network adjusts its parameters based on these penalties, pushing similar instances closer together and dissimilar instances farther apart in the feature space. Once the network is trained, it can be used to rank the severity of new instances. Given a pair of instances, the network computes their feature representations and measures their similarity. The severity ranking is determined by comparing the similarity scores of different pairs. Siamese neural networks have been successfully applied to various tasks, including image similarity, text matching, and recommendation systems. In severity ranking, they can help automate the process of prioritizing and assigning severity levels to different instances based on their similarities and dissimilarities.For example, given pair of image The most common used Loss Function for SSN is Contrastive Loss. Example 1: Let take an example to better understand the model using the above image as reference. Denote A, B \\(\\in R^{224 \\times 224 \\times 3}\\) as 2 images have same size (height \\(\\times\\) width \\(\\times\\) channel). The images then pass through sub-network (Resnet in this case) with shared weight. Assume that the output of each Resnet is \\(\\hat{p}_A \\in R^{1 \\times 2}\\) and \\(\\hat{p}_B \\in R^{1 \\times 2}\\) where \\(\\hat{p}_A\\) denote the probability of A belong to two class, Healthy and Glaucoma, respectively. Then calculate the Euclidian distance between \\(\\hat{p}_A\\) and \\(\\hat{p}_B\\) to get similarity measure following by contrastive loss optimization. \\[ Contrastive Loss = \\frac{1}{2} (1-y) D(\\hat{p}_A, \\hat{p}_B)^2 + \\frac{1}{2} y \\times max(0, D(\\hat{p}_A, \\hat{p}_B)^2 \\] The question now is that how can we get the true label \\(y\\) (1 for similar and 0 for dissimilar) for contrastive loss minimization in case of severity ranking. This can be done by giving pair of image to medical expert and let them label it. Otherwise, consider time domain as landmarks to label similarity. Notice that, in severity ranking, there is no explicit distinction between similarity (1) and dissimilarity (0) but something fuzzy in between 0 and 1. The Achilles of this Similarity Siamese in Severity Ranking is that it learn by Similarity not by the order of images. Thus, ranking information is missing. This can be done by the Preferred Siamese Network which is described in the next sub-section. 3.4.2 Preferred Siamese Network (main focus) We call Siamese Network that use Preferred labels is “Preferred” Siamese Network. These types of network is recently introduced by group of authors [cite]. The main body of Preferred Siamese Network is similar to that of Similarity Siamese. The different is that, the output of each Resnet have dimension of one and the true label \\(y\\) is not similarity measure but preferred measure. Example 2: Let input dimension the same as in example 1. the output of each Resnet have dimension of one, denote severity score \\(\\hat{p}_A\\) and \\(\\hat{p}_B \\in R\\), and the true label \\(y\\) denote “1” as image B have higher degree of severity than image A and “0” as image A have higher degree of severity than image B. "],["images-comparison.html", "Chapter 4 Images Comparison 4.1 Preliminary 4.2 Siaseme Network 4.3 Flow vectors (Special Case)", " Chapter 4 Images Comparison We describe our approaches in this chapter. We will explain the concepts using example of medical images. 4.1 Preliminary Definition 1 (Comparison labels): A comparison label defines a greater or less operation between two objects with respect to some pre-defined criteria. For instance, John and Alice both have brain tumors. The doctor scans images of their brain by MRT and says that John’s health condition is more severe than Alice’s condition. Thus, the MRT-brain images of John are more severe than Alice’s. In other words, John’s image is greater than Alice’s in the sense of tumor severity. Remember that the definition of comparison labels in this document (greater/less than) is different from the definition in learn-to-rank for search engines (similar/dissimilar). If you are familiar with search engines, then this may confuse you. 4.2 Siaseme Network 4.3 Flow vectors (Special Case) In this subsection, we will investigate a special case of comparison. We consider images of the same object, same angle but taken at different times. For instance, an OCT fundus images from the healthy state to the point when the patient got glaucoma. "],["explain-pair-wise-comparison.html", "Chapter 5 Explain Pair-wise Comparison 5.1 p-LIME 5.2 pGradCAM", " Chapter 5 Explain Pair-wise Comparison Some significant applications are demonstrated in this chapter. Conventionally, the current XAI method only applies to one instance at a time. For instance, the classification model inputs an image and outputs a probability list for each class. Here, we consider ranking problems where we have 2 or more inputs, and we would like to explain the decision of such ranking models based on the correlation of input images. 5.1 p-LIME In this subsection, we will talk about a user-centric explainable method for ranking models. We want to explain the mechanism of DL in a user-friendly way. The user here is not computer scientists or researchers, the end user here is people/domain experts who actually use such explanations for their jobs. 5.2 pGradCAM "],["problems.html", "Chapter 6 Problems 6.1 The training is not converged 6.2 Unbalance datassets 6.3 Unaligned Unregistered datasets", " Chapter 6 Problems 6.1 The training is not converged I usually use one trick to figure out if there is a problem in my model or is training process. It is, take small amount of data and train the model until it overfit 100%. If it not overfit with 100% accuracy then there is something wrong with your model. 6.2 Unbalance datassets In the previous example, we have the unbalance dataset between Glaucoma images and Healthy images, in which the Glaucoma only take 30% of total data. This causes a problem when we are interested in the prediction of the minority class. This lead to the result that when pick a pair of sample, it is likely 2 healthy images is selected. In other words, class label in pair-wise dataset can be 90-10%. Unbalance dataset can push the accuracy high due to bias in prediction (carefully check the code to select balance images pair) 6.3 Unaligned Unregistered datasets In some tasks, it is critical to have perfectly registered images so that the model can easily do the work. For examples, with longtitude comparison, two images should be aligned when compare. Optic nerve should be aligned with optic nerve, blood veins should be aligned when put one images on top of the others. So that, anything changes between images are considered anomalies. "],["explain-pair-wise-comparison-1.html", "Chapter 7 Explain pair-wise comparison", " Chapter 7 Explain pair-wise comparison This section will explain pair of images from pair-wise comparison model. "],["future-work.html", "Chapter 8 Future work", " Chapter 8 Future work This section will explain pair of images from pair-wise comparison model. "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
